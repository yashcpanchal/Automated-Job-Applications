import os
from typing import List, TypedDict, Annotated
import asyncio

from pydantic import BaseModel, Field

# Langchain and Langgraph imports
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END
from langchain_community.tools import BraveSearch

# Models imports
from models.job import Job

# API key imports
from core.config import GOOGLE_API_KEY, BRAVE_SEARCH_API_KEY

class AgentState(TypedDict):
    """
    Represents the state of our job search agent.

    Attributes:
        resume_text: The user's resume content.
        search_prompt: The user's specific search request (e.g., "remote backend jobs").
        search_queries: A list of optimized search queries generated by the LLM.
        retrieved_urls: A list of URLs found by the search tool.
        extracted_jobs: A list of Job objects extracted from the URLs.
        final_jobs: The final, filtered list of jobs to be presented to the user.
    """
    resume_text: str
    search_prompt: str
    search_queries: List[str]
    retrieved_urls: List[str]
    extracted_jobs: List[Job]
    final_jobs: List[Job]

class SearchQueries(BaseModel):
    """List of search queries to use."""
    queries: List[str] = Field(
        ...,
        description="""A list of 3-5 diverse, expert-level search engine queries to find job postings."""
    )

async def craft_query_node(state: AgentState):
    """
    Node 1: Crafts targeted search queries based on the user's resume and prompt.
    """
    resume = state['resume_text']
    prompt = state['search_prompt']

    # Generate the search query here

    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=GOOGLE_API_KEY)
    # Ensuring that the llm sticks to the desired output schema
    structured_llm = llm.with_structured_output(SearchQueries)

    # Define the prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a world-class career assistant and expert at crafting search engine queries.
        Your goal is to help a user find relevant job postings based on their resume and a specific prompt.
        
        Generate a diverse list of 3 to 5 search queries that are likely to yield direct job application links
        on company career pages. The queries should be
        creative and varied to cover different angles of the job search."""),
        ("user", """Here is my resume:
        <resume>
        {resume_text}
        </resume>
        \n\n
        Here is my current search prompt:
        <prompt>
        {search_prompt}
        </prompt>
        \n\n
        Please generate the search queries.""")
    ])

    chain = prompt | structured_llm

    result_model = await chain.ainvoke({
        "resume_text": state['resume_text'],
        "search_prompt": state['search_prompt']
    })

    # queries is defined by the output schema in the SearchQueries class
    print(f"GENERATED QUERIES: {result_model.queries}")
    return {"search_queries": result_model.queries}

async def retrieve_and_parse_node(state: AgentState):
    """
    Node 2: Uses a search tool to find job URLs and then parses each URL to extract job data.
    """
    queries = state['search_queries']
    search_tool = BraveSearch.from_api_key(api_key=BRAVE_SEARCH_API_KEY, search_kwargs={"count": 5})
    all_urls = set() # ensures no duplicates
    search_tasks = [search_tool.ainvoke(query) for query in queries]
    results_list = await asyncio.gather(*search_tasks)

    for results in results_list

    # Fake urls for now

    mock_urls = [
        "https://www.linkedin.com/jobs/view/fake-python-job-1",
        "https://www.indeed.com/viewjob/fake-backend-job-2",
        "https://wellfound.com/l/fake-startup-job-3"
    ]

    extracted_jobs = []

    for url in mock_urls:
        print(f"  -> Parsing {url}")
        # llm_extraction_prompt = f"Extract the job details from this page text... into this JSON schema: {Job.model_json_schema()}"
        # page_content = fetch_page(url)
        # extracted_data = llm.invoke(llm_extraction_prompt)
        mock_job = Job(
            title=f"Mock Job from {url.split('.')[1]}",
            company=f"Mock Company Inc.",
            location="Remote",
            description=f"This is a mock description for a job found at {url}.",
            application_url=url,
            source_url=url
        )
        extracted_jobs.append(mock_job)

    return {"retrieved_urls": mock_urls, "extracted_jobs": extracted_jobs}

async def process_and_match_node(state: AgentState):
    """
    Node 3: Filters the extracted jobs for relevance against the user's resume.
    """
    print("--- NODE: PROCESSING AND MATCHING JOBS ---")
    extracted_jobs = state['extracted_jobs']
    resume_text = state['resume_text']
    
    # TODO: Implement the final filtering logic.
    # This is where we could use semantic search (vector similarity) to compare
    # each job description to the user's resume text.
    print("INFO: Filtering jobs for relevance (mock implementation)...")
    
    # For now, we'll just assume all extracted jobs are relevant.
    final_jobs = extracted_jobs
    
    return {"final_jobs": final_jobs}


class JobSearchService:
    def __init__(self):
        workflow = StateGraph(AgentState)

        # Add the nodes to the graph
        workflow.add_node("craft_query", craft_query_node)
        workflow.add_node("retrieve_and_parse", retrieve_and_parse_node)
        workflow.add_node("process_and_match", process_and_match_node)

        # Set the entry and finish points of the graph
        workflow.set_entry_point("craft_query")
        workflow.add_edge("craft_query", "retrieve_and_parse")
        workflow.add_edge("retrieve_and_parse", "process_and_match")
        workflow.add_edge("process_and_match", END)

        # Compile the graph into a runnable application
        self.app = workflow.compile()

    async def search_and_process_jobs(self, resume_text: str, search_prompt: str) -> List[Job]:
        """
        The main method to run the job search agent.
        """
        print("\nðŸš€ --- STARTING AGENTIC JOB SEARCH --- ðŸš€")
        inputs = {"resume_text": resume_text, "search_prompt": search_prompt}
        final_state = await self.app.ainvoke(inputs)
        print("âœ… --- AGENTIC JOB SEARCH COMPLETE --- âœ…\n")
        
        return final_state.get('final_jobs', [])
