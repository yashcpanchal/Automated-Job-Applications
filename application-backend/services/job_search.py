import os
from typing import List, TypedDict, Annotated

# Langchain and Langgraph imports
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.messages import BaseMessage, SystemMessage
from langgraph.graph import StateGraph, END

# Models imports
from models.job import Job


class AgentState(TypedDict):
    """
    Represents the state of our job search agent.

    Attributes:
        resume_text: The user's resume content.
        search_prompt: The user's specific search request (e.g., "remote backend jobs").
        search_queries: A list of optimized search queries generated by the LLM.
        retrieved_urls: A list of URLs found by the search tool.
        extracted_jobs: A list of Job objects extracted from the URLs.
        final_jobs: The final, filtered list of jobs to be presented to the user.
    """
    resume_text: str
    search_prompt: str
    search_queries: List[str]
    retrieved_urls: List[str]
    extracted_jobs: List[Job]
    final_jobs: List[Job]


async def craft_query_node(state: AgentState):
    """
    Node 1: Crafts targeted search queries based on the user's resume and prompt.
    """
    resume = state['resume_text']
    prompt = state['search_prompt']

    # Generate the search query here

    mock_queries = [
        f"remote senior python developer jobs",
        f"backend engineer position REST API United States",
        f"fastapi developer job openings 2024"
    ]

    return {"search_queries": mock_queries}

async def retrieve_and_parse_node(state: AgentState):
    """
    Node 2: Uses a search tool to find job URLs and then parses each URL to extract job data.
    """
    queries = state['search_queries']

    # Fake urls for now

    mock_urls = [
        "https://www.linkedin.com/jobs/view/fake-python-job-1",
        "https://www.indeed.com/viewjob/fake-backend-job-2",
        "https://wellfound.com/l/fake-startup-job-3"
    ]

    extracted_jobs = []

    for url in mock_urls:
        print(f"  -> Parsing {url}")
        # llm_extraction_prompt = f"Extract the job details from this page text... into this JSON schema: {Job.model_json_schema()}"
        # page_content = fetch_page(url)
        # extracted_data = llm.invoke(llm_extraction_prompt)
        mock_job = Job(
            title=f"Mock Job from {url.split('.')[1]}",
            company=f"Mock Company Inc.",
            location="Remote",
            description=f"This is a mock description for a job found at {url}.",
            application_url=url,
            source_url=url
        )
        extracted_jobs.append(mock_job)

    return {"retrieved_urls": mock_urls, "extracted_jobs": extracted_jobs}

async def process_and_match_node(state: AgentState):
    """
    Node 3: Filters the extracted jobs for relevance against the user's resume.
    """
    print("--- NODE: PROCESSING AND MATCHING JOBS ---")
    extracted_jobs = state['extracted_jobs']
    resume_text = state['resume_text']
    
    # TODO: Implement the final filtering logic.
    # This is where we could use semantic search (vector similarity) to compare
    # each job description to the user's resume text.
    print("INFO: Filtering jobs for relevance (mock implementation)...")
    
    # For now, we'll just assume all extracted jobs are relevant.
    final_jobs = extracted_jobs
    
    return {"final_jobs": final_jobs}


class JobSearchService:
    def __init__(self):
        workflow = StateGraph(AgentState)

        # Add the nodes to the graph
        workflow.add_node("craft_query", craft_query_node)
        workflow.add_node("retrieve_and_parse", retrieve_and_parse_node)
        workflow.add_node("process_and_match", process_and_match_node)

        # Set the entry and finish points of the graph
        workflow.set_entry_point("craft_query")
        workflow.add_edge("craft_query", "retrieve_and_parse")
        workflow.add_edge("retrieve_and_parse", "process_and_match")
        workflow.add_edge("process_and_match", END)

        # Compile the graph into a runnable application
        self.app = workflow.compile()

    async def search_and_process_jobs(self, resume_text: str, search_prompt: str) -> List[Job]:
        """
        The main method to run the job search agent.
        """
        print("\nðŸš€ --- STARTING AGENTIC JOB SEARCH --- ðŸš€")
        inputs = {"resume_text": resume_text, "search_prompt": search_prompt}
        final_state = await self.app.ainvoke(inputs)
        print("âœ… --- AGENTIC JOB SEARCH COMPLETE --- âœ…\n")
        
        return final_state.get('final_jobs', [])
